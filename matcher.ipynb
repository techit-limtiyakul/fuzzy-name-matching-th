{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_lastname(lname):\n",
    "    #blank lastname in csv >>> NaN in Pandas\n",
    "    return lname=='-' or lname=='0' if isinstance(lname,str) else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person(title):\n",
    "    keywords = ['นาย','นาง','นางสาว']\n",
    "    if title in keywords:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person_name(name):\n",
    "    keywords = ['นาย','นาง','นางสาว','คุณหญิง','น.ส.','ม.ล.','พล.ท.','ร.ท.','พ.ต.ท.','ม.ร.ว.','DR.','MR.','MRS.','ร.ต.ท.','ด.ญ.','ด.ช.','ว่าที่ ร.ต.','รองศาสตราจารย์','ดร.','รศ.','ผศ.']\n",
    "    for keyword in keywords:\n",
    "        if not isinstance(name, str):\n",
    "            print(name)\n",
    "            break\n",
    "        if name.find(keyword) == 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the name is all eng.\n",
    "def is_eng(name):\n",
    "    eng_re = re.compile('^([a-zA-Z0-9-_().,\\s/&+\\'\\\"])*$')\n",
    "    if eng_re.match(name):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop out spaces and .\n",
    "def drop_separators(str):\n",
    "    try:\n",
    "        return str.replace('.','').replace(' ','')\n",
    "    except:\n",
    "        print('cannot process:',str)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_common_words(str):\n",
    "    common_words = ['บริษัท','จำกัด','(ประเทศไทย)','(มหาชน)']\n",
    "    out = str\n",
    "    try:\n",
    "        for word in common_words:\n",
    "            out = out.replace(word, '')\n",
    "    except:\n",
    "        print('cannot process:',str)\n",
    "        return ''\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_name(str):\n",
    "    return drop_common_words(drop_separators(str)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the id's and the jaro scores for the top k matches of a firm name\n",
    "#name = firm name to match. The name will be matched against the whole master file\n",
    "#count = number of top matches\n",
    "##############################\n",
    "def get_top_matches(name, master, count=10):\n",
    "    dist = master['mod_name'].apply(lambda a: jellyfish.jaro_distance(a,name))\n",
    "    topk = dist.nlargest(count)\n",
    "    indices = topk.index.values\n",
    "    ids = master['jrst_id'][indices]\n",
    "    return ids.values, topk.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query_file(path):\n",
    "    try:\n",
    "        query = pd.read_csv(path)\n",
    "    except:\n",
    "        #thai\n",
    "        query = pd.read_csv(path, encoding='cp874')\n",
    "        \n",
    "    #rename idx\n",
    "    query = query.rename({'เลขทะเบียน':'id','คำนำหน้า':'title','ชื่อ':'name','สกุล':'lname','สัญชาติ':'nat','อาชีพ':'occ','จำนวนหุ้นที่ถือ':'stock'},axis='columns')\n",
    "\n",
    "    #drop dup\n",
    "    query = query.drop_duplicates()\n",
    "\n",
    "    #dropping unused\n",
    "    query = query.drop(['stock'],axis=1)\n",
    "\n",
    "    #filter only th. nat\n",
    "    query = query[query['nat'] == 'TH']\n",
    "\n",
    "    #select only ones without last name\n",
    "    query = query[query['lname'].apply(no_lastname)]\n",
    "    \n",
    "    #filter out using title\n",
    "    query = query[~query['title'].apply(is_person)]\n",
    "    \n",
    "    #filter ppl out using name\n",
    "    query = query[~query['name'].apply(is_person_name)]    \n",
    "\n",
    "    query['mod_name'] = query['name'].apply(preprocess_name)\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_master_file(path):\n",
    "    master = pd.read_csv(path)\n",
    "\n",
    "    master = master.drop_duplicates()\n",
    "\n",
    "    #drop nan (last element is a nan)\n",
    "    master = master.dropna(subset=['jrst_nm'])\n",
    "\n",
    "    #drop unused column\n",
    "    master = master.drop([\n",
    "        'source'\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "    #rename column\n",
    "    master = master.rename({'jrst_nm':'name_2'},axis='columns')\n",
    "\n",
    "    #define a temporary column containing modified firm names for matching purpose\n",
    "    master['mod_name'] = master['name_2'].apply(preprocess_name)\n",
    "    \n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches two pandas dataframe,\n",
    "#Query file needs name and mod_name column\n",
    "def match(query, master, output_prefix):\n",
    "    merged = pd.merge(query,master,on=['mod_name'],how='inner')\n",
    "\n",
    "    try:\n",
    "        #drop unused columns\n",
    "        merged = merged.drop(['nat', 'occ', 'lname','mod_name'],axis=1)\n",
    "        \n",
    "        #rename columns\n",
    "        merged = merged.rename({'jrst_id':'id_in_master','name_2':'name_in_master'}, axis=1)\n",
    "    except e:\n",
    "        pass\n",
    "    \n",
    "    #drop duplicates\n",
    "    merged.drop_duplicates()\n",
    "\n",
    "    #save\n",
    "    merged.to_csv('{}_merged.csv'.format(output_prefix))\n",
    "\n",
    "    #get unmatched names\n",
    "    unmatched = query[~query['name'].isin(merged['name'])]\n",
    "\n",
    "    #restart index number from 1\n",
    "    unmatched = unmatched.reset_index(drop=True)\n",
    "\n",
    "    #remove matched names\n",
    "    #edit: Can't -- sometimes there are more than one flavors of the same name where one perfectly matches and others don't.\n",
    "    #master = master[~master['name_2'].isin(merged['name'])]\n",
    "\n",
    "    #create columns for similarity\n",
    "    unmatched['jrst_id'], unmatched['sim_score'] = 0,0.0\n",
    "\n",
    "    #indices for the newly created columns\n",
    "    idloc = unmatched.columns.get_loc('jrst_id')\n",
    "    scoreloc = unmatched.columns.get_loc('sim_score')\n",
    "\n",
    "    #create empty placeholder for matched data\n",
    "    partial_match = pd.DataFrame(columns=unmatched.columns)\n",
    "\n",
    "    size = unmatched.shape[0]\n",
    "    for i in tqdm(range(unmatched.shape[0])):\n",
    "        firm_name = unmatched['mod_name'][i]\n",
    "        #get top k matches\n",
    "        ids, scores = get_top_matches(firm_name, master)\n",
    "#         print(\"{} of {}\".format(i, size))\n",
    "        #add all top k matches to the placeholder\n",
    "        for j in range(len(ids)):\n",
    "            #first, modify the original query set\n",
    "            unmatched.iat[i,idloc] = ids[j]\n",
    "            unmatched.iat[i,scoreloc] = scores[j]\n",
    "            #copy the original row to the new dataframe\n",
    "            partial_match = partial_match.append(unmatched.loc[i])\n",
    "\n",
    "    partial_match = pd.merge(partial_match, master[['jrst_id','name_2']],on=['jrst_id'],how='left')\n",
    "\n",
    "    partial_match = partial_match.rename({'jrst_id':'id_in_master','name_2':'name_in_master'}, axis=1)\n",
    "\n",
    "    try:\n",
    "        partial_match = partial_match.drop(['nat', 'occ', 'lname', 'mod_name'], axis=1)\n",
    "    except e:\n",
    "        pass\n",
    "\n",
    "    partial_match.to_csv('{}_partial.csv'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = './output/'\n",
    "input_path = './queryfiles/'\n",
    "master_filename = './master.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(input_path)\n",
    "files = list(filter(lambda s: '.csv' in s, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./queryfiles/TS_10-60-108121_007.csv\n",
      "===============================================\n",
      "Processing file 1 of 1\n",
      "===============================================\n",
      "nan\n",
      "cannot process: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/295 [00:03<07:47,  1.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-fce08a86b05f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_query_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_master_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-e8a42ffe65ec>\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(query, master, output_prefix)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mfirm_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munmatched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mod_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#get top k matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirm_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#         print(\"{} of {}\".format(i, size))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#add all top k matches to the placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-4468e0479b52>\u001b[0m in \u001b[0;36mget_top_matches\u001b[0;34m(name, master, count)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m##############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_top_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mod_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjellyfish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaro_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-4468e0479b52>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m##############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_top_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mod_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjellyfish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaro_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for file in files: \n",
    "    print(input_path+file)\n",
    "    idx = idx + 1\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('Processing file {} of {}'.format(idx,len(files)))\n",
    "    print('===============================================')\n",
    "\n",
    "    prefix = file[:-4]\n",
    "    query = preprocess_query_file(input_path+file)\n",
    "    master = preprocess_master_file(master_filename)\n",
    "    match(query, master, output_path+prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case for SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_q = pd.read_csv('./SET_Ownership_Techit.csv')\n",
    "\n",
    "#rename for matching\n",
    "set_q = set_q.rename({'holder_name_o':'name'},axis='columns')\n",
    "\n",
    "#drop blank cols\n",
    "set_q = set_q.drop([\"Unnamed: 2\", \"Unnamed: 3\",\"Unnamed: 4\"], axis='columns')\n",
    "\n",
    "#drop dups\n",
    "set_q = set_q.drop_duplicates()\n",
    "\n",
    "#filter ppl out using name\n",
    "set_q = set_q[~set_q['name'].apply(is_person_name)]    \n",
    "\n",
    "#filter out full eng names\n",
    "set_q = set_q[~set_q['name'].apply(is_eng)]\n",
    "\n",
    "set_q['mod_name'] = set_q['name'].apply(preprocess_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'name', 'mod_name'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = preprocess_master_file(master_filename)\n",
    "match(set_q, master, './output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./master.csv'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/TS_10-60-108121_007'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path+prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
