{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_lastname(lname):\n",
    "    #blank lastname in csv >>> NaN in Pandas\n",
    "    return lname=='-' or lname=='0' if isinstance(lname,str) else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person(title):\n",
    "    keywords = ['นาย','นาง','นางสาว']\n",
    "    if title in keywords:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person_name(name):\n",
    "    keywords = ['นาย','นาง','นางสาว','คุณหญิง','น.ส.','ม.ล.','พล.ท.','ร.ท.','พ.ต.ท.','ม.ร.ว.','DR.','MR.','MRS.']\n",
    "    for keyword in keywords:\n",
    "        if not isinstance(name, str):\n",
    "            print(name)\n",
    "            break\n",
    "        if name.find(keyword) == 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop out spaces and .\n",
    "def drop_separators(str):\n",
    "    try:\n",
    "        return str.replace('.','').replace(' ','')\n",
    "    except:\n",
    "        print('cannot process:',str)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_common_words(str):\n",
    "    common_words = ['บริษัท','จำกัด','(ประเทศไทย)','(มหาชน)']\n",
    "    out = str\n",
    "    try:\n",
    "        for word in common_words:\n",
    "            out = out.replace(word, '')\n",
    "    except:\n",
    "        print('cannot process:',str)\n",
    "        return ''\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_name(str):\n",
    "    return drop_common_words(drop_separators(str)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the id's and the jaro scores for the top k matches of a firm name\n",
    "#name = firm name to match. The name will be matched against the whole master file\n",
    "#count = number of top matches\n",
    "##############################\n",
    "def get_top_matches(name, master, count=10):\n",
    "    dist = master['mod_name'].apply(lambda a: jellyfish.jaro_distance(a,name))\n",
    "    topk = dist.nlargest(count)\n",
    "    indices = topk.index.values\n",
    "    ids = master['jrst_id'][indices]\n",
    "    return ids.values, topk.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(query_filename, master_filename, output_prefix):\n",
    "    try:\n",
    "        query = pd.read_csv(query_filename)\n",
    "    except:\n",
    "        #thai\n",
    "        query = pd.read_csv(query_filename, encoding='cp874')\n",
    "        \n",
    "    master = pd.read_csv(master_filename)\n",
    "\n",
    "    #rename idx\n",
    "    query = query.rename({'เลขทะเบียน':'id','คำนำหน้า':'title','ชื่อ':'name','สกุล':'lname','สัญชาติ':'nat','อาชีพ':'occ','จำนวนหุ้นที่ถือ':'stock'},axis='columns')\n",
    "\n",
    "    #drop dup\n",
    "    query = query.drop_duplicates()\n",
    "\n",
    "    #dropping unused\n",
    "    query = query.drop(['stock'],axis=1)\n",
    "\n",
    "    #filter only th. nat\n",
    "    query = query[query['nat'] == 'TH']\n",
    "\n",
    "    #select only ones without last name\n",
    "    query = query[query['lname'].apply(no_lastname)]\n",
    "    \n",
    "    #filter out using title\n",
    "    query = query[~query['title'].apply(is_person)]\n",
    "    \n",
    "    #filter ppl out using name\n",
    "    query = query[~query['name'].apply(is_person_name)]\n",
    "    \n",
    "    master = master.drop_duplicates()\n",
    "\n",
    "    #drop nan (last element is a nan)\n",
    "    master = master.dropna(subset=['jrst_nm'])\n",
    "\n",
    "    #drop unused column\n",
    "    master = master.drop([\n",
    "        'source'\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "    #rename column\n",
    "    master = master.rename({'jrst_nm':'name_2'},axis='columns')\n",
    "\n",
    "    #define a temporary column containing modified firm names for matching purpose\n",
    "    master['mod_name'] = master['name_2'].apply(preprocess_name)\n",
    "    query['mod_name'] = query['name'].apply(preprocess_name)\n",
    "\n",
    "    merged = pd.merge(query,master,on=['mod_name'],how='inner')\n",
    "\n",
    "    #drop temporary column\n",
    "    merged = merged.drop(['mod_name'],axis=1)\n",
    "\n",
    "    #drop unused columns\n",
    "    merged = merged.drop(['nat', 'occ', 'lname'],axis=1)\n",
    "\n",
    "    #rename columns\n",
    "    merged = merged.rename({'jrst_id':'id_in_master','name_2':'name_in_master'}, axis=1)\n",
    "\n",
    "    #save\n",
    "    merged.to_csv('{}_merged.csv'.format(output_prefix))\n",
    "\n",
    "    #get unmatched names\n",
    "    unmatched = query[~query['name'].isin(merged['name'])]\n",
    "\n",
    "    #restart index number from 1\n",
    "    unmatched = unmatched.reset_index(drop=True)\n",
    "\n",
    "    #remove matched names\n",
    "    #edit: Can't -- sometimes there are more than one flavors of the same name where one perfectly matches and others don't.\n",
    "    #master = master[~master['name_2'].isin(merged['name'])]\n",
    "\n",
    "    #create columns for similarity\n",
    "    unmatched['jrst_id'], unmatched['sim_score'] = 0,0.0\n",
    "\n",
    "    #indices for the newly created columns\n",
    "    idloc = unmatched.columns.get_loc('jrst_id')\n",
    "    scoreloc = unmatched.columns.get_loc('sim_score')\n",
    "\n",
    "    #create empty placeholder for matched data\n",
    "    partial_match = pd.DataFrame(columns=unmatched.columns)\n",
    "\n",
    "    size = unmatched.shape[0]\n",
    "    for i in tqdm(range(unmatched.shape[0])):\n",
    "        firm_name = unmatched['mod_name'][i]\n",
    "        #get top k matches\n",
    "        ids, scores = get_top_matches(firm_name, master)\n",
    "#         print(\"{} of {}\".format(i, size))\n",
    "        #add all top k matches to the placeholder\n",
    "        for j in range(len(ids)):\n",
    "            #first, modify the original query set\n",
    "            unmatched.iat[i,idloc] = ids[j]\n",
    "            unmatched.iat[i,scoreloc] = scores[j]\n",
    "            #copy the original row to the new dataframe\n",
    "            partial_match = partial_match.append(unmatched.loc[i])\n",
    "\n",
    "    partial_match = pd.merge(partial_match, master[['jrst_id','name_2']],on=['jrst_id'],how='left')\n",
    "\n",
    "    partial_match = partial_match.drop(['nat', 'occ', 'lname', 'mod_name'], axis=1)\n",
    "    partial_match = partial_match.rename({'jrst_id':'id_in_master','name_2':'name_in_master'}, axis=1)\n",
    "\n",
    "\n",
    "    partial_match.to_csv('{}_partial.csv'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_path = './output/'\n",
    "input_path = './queryfiles/'\n",
    "master_filename = './master.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(input_path)\n",
    "files = list(filter(lambda s: '.csv' in s, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./queryfiles/TS_10-61-109055_000.csv\n",
      "===============================================\n",
      "Processing file 1 of 1\n",
      "===============================================\n",
      "nan\n",
      "cannot process: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 219/3406 [06:24<1:33:16,  1.76s/it]"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for file in files: \n",
    "    print(input_path+file)\n",
    "    idx = idx + 1\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('Processing file {} of {}'.format(idx,len(files)))\n",
    "    print('===============================================')\n",
    "\n",
    "    query_filename = file\n",
    "    prefix = file[:-4]\n",
    "    match(input_path+'/'+query_filename, master_filename, output_path+prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
